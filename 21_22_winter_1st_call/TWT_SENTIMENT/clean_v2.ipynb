{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dev_path = '../DSL2122_january_dataset/development.csv'\n",
    "eva_path = '../DSL2122_january_dataset/evaluation.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 224994 entries, 0 to 224993\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   sentiment  224994 non-null  int64 \n",
      " 1   ids        224994 non-null  int64 \n",
      " 2   date       224994 non-null  object\n",
      " 3   flag       224994 non-null  object\n",
      " 4   user       224994 non-null  object\n",
      " 5   text       224994 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dev_ds = pd.read_csv(dev_path, low_memory=True)\n",
    "dev_ds.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dev_ds.drop(columns=['ids', 'flag'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ooweey\\AppData\\Roaming\\Python\\Python39\\site-packages\\dateutil\\parser\\_parser.py:1213: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Hours of day coresponding to the part of the day\n",
    "\n",
    "morning [5 - 12] -> 0.2\n",
    "afternoon [13 - 18] -> 0.4\n",
    "evening [19 - 22] -> 0.6\n",
    "night [23 - 5] -> 0.8\n",
    "'''\n",
    "\n",
    "def hourToPartOfDay(hour):\n",
    "    if hour < 4:\n",
    "        return 0.8\n",
    "    elif hour < 12:\n",
    "        return 0.2\n",
    "    elif hour < 18:\n",
    "        return 0.4\n",
    "    elif hour < 23:\n",
    "        return 0.6\n",
    "    else:\n",
    "        return 0.8\n",
    "\n",
    "dev_ds['date'] = pd.to_datetime(dev_ds['date'])\n",
    "dev_ds['month'] = pd.DatetimeIndex(dev_ds['date']).month\n",
    "dev_ds['day'] = pd.DatetimeIndex(dev_ds['date']).day\n",
    "dev_ds['hour'] = pd.DatetimeIndex(dev_ds['date']).hour\n",
    "\n",
    "dev_ds['part_of_day'] = dev_ds.hour.apply(lambda x: hourToPartOfDay(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dev_ds.drop(columns=['date'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "prob_positive = dev_ds.groupby(['user'])['sentiment']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def encode_users(df):\n",
    "    probs = pd.DataFrame(df.groupby(['user'])['sentiment'].mean())\n",
    "\n",
    "    # creating ratio between neg and pos\n",
    "    probs['neg'] = 1 - probs['sentiment']\n",
    "    probs['ratio'] = probs['sentiment'] / probs['neg']\n",
    "\n",
    "    # removing infinite values\n",
    "    probs['ratio'] = probs.ratio.map(lambda x: 80 if x == np.inf else x )\n",
    "\n",
    "    enc_prob_ratio = probs.ratio.to_dict()\n",
    "\n",
    "    df['encoded_usr'] = dev_ds['user'].map(enc_prob_ratio)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dev_ds = encode_users(dev_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# text processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# cleaning text\n",
    "\n",
    "remove_tag = lambda x: re.sub(r'[@]\\w+[a-zA-Z0-9] ', '',x)\n",
    "remove_punct = lambda x: re.sub(r'[^\\w\\s]', '', x)\n",
    "remove_links = lambda x: re.sub(r'http\\w+[a-zA-Z0-9] ', '', x)\n",
    "remove_strange_chars = lambda x: x.encode(\"ascii\", \"ignore\").decode()\n",
    "remove_repeated_chars = lambda x: re.sub(r'(.)\\1+', r'\\1', x)\n",
    "\n",
    "dev_ds['cl_text'] = dev_ds.text.map(remove_tag)\\\n",
    "                                    .map(remove_punct)\\\n",
    "                                    .map(remove_links)\\\n",
    "                                    .map(remove_strange_chars)\\\n",
    "                                    .apply(str.lower)\n",
    "\n",
    "dev_ds['cl_text'] = dev_ds['cl_text'].map(remove_repeated_chars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# def cleaning_repeating_char(text):\n",
    "#     return re.sub(r'(.)1+', r'1', text)\n",
    "#\n",
    "# dev_ds['cl_text'] = dev_ds['cl_text'].apply(lambda x: cleaning_repeating_char(x))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# tokenizing the tweet\n",
    "\n",
    "tokenize =  lambda x: re.split('\\W+', x)\n",
    "\n",
    "dev_ds['tokenized'] = dev_ds.cl_text.map(tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "most of the tweets contains a last empty char, cleaning again"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def clean_tokenized(text): # change name\n",
    "    text = [w for w in text if len(w) > 1]\n",
    "    return text\n",
    "dev_ds['tokenized'] = dev_ds['tokenized'].apply(lambda x: clean_tokenized(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    if len(text) < 4: return text\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "dev_ds['no_stop_words'] = dev_ds.tokenized.apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "dev_ds['len_tweet'] = dev_ds.no_stop_words.apply(len)\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "dev_ds['stemmed'] = dev_ds.no_stop_words.apply(lambda x: stemming(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dev_ds.drop(columns=['text', 'cl_text', 'user', 'tokenized', 'no_stop_words'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "mask = dev_ds['sentiment'] == 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "pos_data = dev_ds[mask].drop(columns=['month', 'day', 'hour', 'part_of_day', 'encoded_usr', 'len_tweet'])\n",
    "neg_data = dev_ds[~mask].drop(columns=['month', 'day', 'hour', 'part_of_day', 'encoded_usr', 'len_tweet'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "((130157, 3), (94837, 3))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_data = neg_data.reset_index()\n",
    "pos_data = pos_data.reset_index()\n",
    "\n",
    "pos_data.shape, neg_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "tot_wc = WordCloud(max_words=10000, width = 3980 , height = 2080,\n",
    "               collocations=False).generate(\" \".join(dev_ds['stemmed'].str.join(' ')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# pos_data = pos_data['stemmed'].str.join(' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# wc = WordCloud(max_words = 1000 , width = 3980 , height = 2080,\n",
    "#                collocations=False).generate(\" \".join(pos_data['stemmed'].str.join(' ')))\n",
    "# plt.imshow(wc)\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "# wc = WordCloud(max_words = 1000 , width = 3980 , height = 2080,\n",
    "#                collocations=False).generate(\" \".join(neg_data['stemmed'].str.join(' ')))\n",
    "# plt.imshow(wc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(130157, 1099)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,3),\n",
    "                     min_df=0.0001,\n",
    "                     tokenizer=dummy,\n",
    "                     preprocessor=dummy)\n",
    "pos_tfidf = tf.fit_transform(pos_data['stemmed'])\n",
    "\n",
    "pos_df_tfidf = pd.DataFrame(pos_tfidf.toarray(), columns=tf.get_feature_names())\n",
    "\n",
    "pos_df_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "p_data = pos_data[['sentiment']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "((130157, 1), (130157, 1099))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape, pos_df_tfidf.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(130157, 1099)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(130157, 1100)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating the pos values with the tfidf\n",
    "\n",
    "datasets = [p_data, pos_df_tfidf]\n",
    "pos_df_tfidf = pd.concat(datasets, axis=1)\n",
    "\n",
    "pos_df_tfidf.shape\n",
    "# sys.getsizeof(dev_ds)/1073741824"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# del pos_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# corr = pos_df_tfidf.corr()\n",
    "\n",
    "# data = dev_ds['stemmed'].str.join(' ')\n",
    "\n",
    "# plt.figure(figsize = (50,50))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# wc = WordCloud(max_words = 1000 , width = 1980 , height = 1080,\n",
    "#                collocations=False).generate(\" \".join(data))\n",
    "# plt.imshow(wc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "'''\n",
    "q(d) = the quality score\n",
    "d = review\n",
    "D = the collection of documents\n",
    "I(t, d) = indicator function whose value is 1 if d contains the term t and -1 otherwise\n",
    "|D| Pd02D q(d0) = average quality score\n",
    "'''\n",
    "\n",
    "def avg_quality_score(df):\n",
    "    return df['sentiment'].mean()\n",
    "\n",
    "def indicator(w, t):\n",
    "    return 1 if w in t else -1\n",
    "\n",
    "\n",
    "def get_word_corr(w, df, avg, ind_text, ind_sent):\n",
    "    D = len(df.index)\n",
    "    ssum = 0\n",
    "\n",
    "\n",
    "    for el in df.values:\n",
    "        ind = indicator(w, el[ind_text])\n",
    "        q_d = el[ind_sent]\n",
    "\n",
    "        ssum += (ind * (q_d - avg))\n",
    "\n",
    "    return ssum / D\n",
    "\n",
    "def word_score_correlation(bag, df):\n",
    "    cors = {}\n",
    "    avg_qual = avg_quality_score(df)\n",
    "    col_text = list(df.columns).index('stemmed')\n",
    "    col_sent = list(df.columns).index('sentiment')\n",
    "\n",
    "    for w in bag:\n",
    "        value = get_word_corr(w, df, avg_qual, col_text, col_sent)\n",
    "        cors[w] = value\n",
    "\n",
    "    return cors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "ls = list(tot_wc.words_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "wsc = word_score_correlation(ls, dev_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "wsc = {k: v for k, v in sorted(wsc.items(), key=lambda item: item[1], reverse=True)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "words = list(wsc.items())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "pos_words = words[0:2000]\n",
    "neg_words = words[-2000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "(224994, 9703)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,3),\n",
    "                     min_df=0.0001,\n",
    "                     tokenizer=dummy,\n",
    "                     preprocessor=dummy)\n",
    "pos_tfidf = tf.fit_transform(dev_ds['stemmed'])\n",
    "\n",
    "full_pos_df_tfidf = pd.DataFrame(pos_tfidf.toarray(), columns=tf.get_feature_names())\n",
    "\n",
    "full_pos_df_tfidf.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def fin_df_tr(pos, neg, df):\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col == 'sentiment':\n",
    "            continue\n",
    "        if (col not in pos) and (col not in neg):\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "sent_df = dev_ds[['sentiment']]\n",
    "\n",
    "datasets = [sent_df, full_pos_df_tfidf]\n",
    "full_df_tr = pd.concat(datasets, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "ls_1 = full_df_tr.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "ls_1 = list(ls_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-9f4e7ab1",
   "language": "python",
   "display_name": "PyCharm (gpt_eval_repl)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}