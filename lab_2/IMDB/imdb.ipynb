{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter,OrderedDict\n",
    "import csv\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\CERTIM~1\\AppData\\Local\\Temp/ipykernel_18792/1157090191.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'imdb.txt'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'UTF-8'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mreader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcsv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[0mnext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreader\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#skip header\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "reviews, labels = [], []\n",
    "\n",
    "with open('imdb.txt', encoding='UTF-8') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    next(reader) #skip header\n",
    "\n",
    "    for row in reader:\n",
    "        reviews.append(row[0])\n",
    "        labels.append(row[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def tokenize(docs):\n",
    "    \"\"\"\n",
    "    Compute the tokens for each document.\n",
    "\n",
    "    :param docs: list of strings. Each item is a document to tokenize.\n",
    "    :return: list of lists. Each item is a list containing the tokens of the relative doc\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "\n",
    "    for doc in docs:\n",
    "        for puncts in string.punctuation:\n",
    "            doc = doc.replace(puncts, ' ')\n",
    "\n",
    "        split_doc = [token.lower() for token in doc.split() if token]\n",
    "        tokens.append(split_doc)\n",
    "\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_tf(doc):\n",
    "    tf = {}\n",
    "\n",
    "    for token in doc:\n",
    "        if token not in tf:\n",
    "            tf[token] = 0\n",
    "        tf[token] += 1\n",
    "\n",
    "    return tf\n",
    "\n",
    "def compute_TF(docs):\n",
    "    tf_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        tf_docs.append(get_tf(doc))\n",
    "\n",
    "    return tf_docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "reviews = tokenize(reviews)\n",
    "tf_reviews = compute_TF(reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# def get_df(token, docs):\n",
    "#     c = 0\n",
    "#     for doc in docs:\n",
    "#         if token in doc:\n",
    "#             c +=1\n",
    "#     return c\n",
    "#\n",
    "# def compute_DF(docs):\n",
    "#     toks = {}\n",
    "#\n",
    "#     for doc in docs:\n",
    "#         for token in doc:\n",
    "#             if token not in toks:\n",
    "#                 toks[token] = get_df(token, docs)\n",
    "#\n",
    "#     return docs\n",
    "#\n",
    "# def compute_IDF(docs, tdf):\n",
    "#     N = len(docs)\n",
    "#\n",
    "#     for key in tdf.keys():\n",
    "#         tdf[key] = math.log(N/tdf[key])\n",
    "#\n",
    "#     return tdf\n",
    "#\n",
    "# def sort_IDF(tdf):\n",
    "#     dict1 = OrderedDict(sorted(tdf.items()))\n",
    "#     print(dict1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def compute_idf(docs):\n",
    "    DF = {}\n",
    "    N = len(docs)\n",
    "\n",
    "    # compute the document-frequency (DF), i.e. the number of documents in which each token appears at least once\n",
    "    for doc in docs:\n",
    "        for token, token_tf in doc.items():\n",
    "            DF[token] = DF.get(token, 0) +1\n",
    "\n",
    "    # compute actual IDF\n",
    "    return {token : math.log(N/df) for token, df in DF.items()}\n",
    "\n",
    "df_tokens = compute_idf(tf_reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "sorted_view = sorted(df_tokens.items(), key = lambda item: item[1])\n",
    "# key indicates what to take in consideration for the sorting, the key or the\n",
    "# value of the pair returned by the dictionary.items()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_view[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def norm(d):\n",
    "    return sum([value**2 for t, value in d.items()])**.5\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    # only the words that appear in at least one of the two vectors/documents are involved\n",
    "    dict_d = set(list(v1.keys()) + list(v2.keys()))\n",
    "    return sum([(v1.get(d, 0.0) * v2.get(d, 0.0)) for d in dict_d])\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2) / (norm(v1) * norm(v2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\CERTIM~1\\AppData\\Local\\Temp/ipykernel_18792/2309814414.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Document (0) and document (1) have cosine similarity:'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcosine_similarity\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf_reviews\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtf_reviews\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print('Document (0) and document (1) have cosine similarity:', cosine_similarity(tf_reviews[0], tf_reviews[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "We can now compute the similarities and then assign the class label accordingly.\n",
    "In order to optimize the evaluation we can exploit the fact that the cosine similarity is a\n",
    "commutative operator, i.e.  cos(V1,V2)=cos(V2,V1) . In this sense, we can encode similarities\n",
    "between each pair of reviews in a symmetric matrix and then use it to compute the average with\n",
    "respect to the positive and negative sets.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "pos_i = [i for i, label in enumerate(labels) if label == '1']\n",
    "neg_i = [i for i, label in enumerate(labels) if label == '0']\n",
    "print(len(pos_i), len(neg_i))\n",
    "\n",
    "similarities = []\n",
    "y_true = labels\n",
    "y_pred = []\n",
    "r_len = len(df_tokens)\n",
    "try:\n",
    "    for i, r1 in enumerate(df_tokens):\n",
    "        store_sim = []\n",
    "        curr_sim = []\n",
    "        for j, r2 in enumerate(df_tokens):\n",
    "            if j == i:\n",
    "                curr_sim.append(-1) # this value will never be used\n",
    "            elif j < i:\n",
    "                curr_sim.append(similarities[j][i-j-1]) # reuse the similarities already evaluated\n",
    "            else:\n",
    "                s = cosine_similarity(df_tokens[j], df_tokens[i])\n",
    "                store_sim.append(s)\n",
    "                curr_sim.append(s)\n",
    "        similarities.append(store_sim) # store only the similarities computed in this iteration\n",
    "\n",
    "        if i in pos_i:\n",
    "            p_mask = pos_i.copy()\n",
    "            p_mask.pop(i)\n",
    "            n_mask = neg_i\n",
    "        else:\n",
    "            p_mask = pos_i\n",
    "            n_mask = neg_i.copy()\n",
    "            n_mask.pop(i)\n",
    "\n",
    "        p_mean = np.array(curr_sim)[p_mask].mean()\n",
    "        n_mean = np.array(curr_sim)[n_mask].mean()\n",
    "\n",
    "        if p_mean > n_mean:\n",
    "            y_pred.append('1')\n",
    "        else:\n",
    "            y_pred.append('0')\n",
    "\n",
    "        print(f'{100*i/(r_len):.2f}%', end='\\r')\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nInterrupted')\n",
    "    pred_c = len(y_pred)\n",
    "    correct = sum([1 for t, p in zip(y_pred, y_true[:pred_c]) if t == p])\n",
    "    print(f'Computed {i} reviews up to now. Accuracy: {correct/pred_c * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}